# Titan-Stream å®æ–½é—®é¢˜ä¿®å¤è®¡åˆ’

## æ–‡æ¡£ç›®çš„
æœ¬æ–‡æ¡£è®°å½•äº† Titan-Stream (M-Stream V9) å®æ–½è¿‡ç¨‹ä¸­å‘ç°çš„è®¾è®¡åç¦»é—®é¢˜ï¼Œå¹¶æä¾›è¯¦ç»†çš„ä¿®å¤æ–¹æ¡ˆå’Œå®æ–½è®¡åˆ’ã€‚

---

## ä¸€ã€é—®é¢˜æ¸…å•

### ğŸ”´ P0 - å¿…é¡»ä¿®å¤ï¼ˆå½±å“æ ¸å¿ƒè®¾è®¡ï¼‰

#### é—®é¢˜ 1ï¼šç¦»çº¿è®­ç»ƒæœªæ¨¡æ‹Ÿåœ¨çº¿è®°å¿†æ¼”åŒ–

**é—®é¢˜æè¿°**ï¼š
- è®¾è®¡è¦æ±‚ï¼šChunk å¾ªç¯æ¨¡æ‹Ÿåœ¨çº¿æµï¼Œè®°å¿†çŠ¶æ€ M_t è·¨ Chunk å»¶ç»­
- å®é™…å®ç°ï¼šè®­ç»ƒæ—¶ä½¿ç”¨ `use_state=False`ï¼Œæ¯ä¸ª Chunk éƒ½ä½¿ç”¨å›ºå®šçš„ `memory_init`ï¼Œè®°å¿†ä¸å»¶ç»­

**ä»£ç ä½ç½®**ï¼š`exp/exp_long_term_forecasting.py:208-215`
```python
# å½“å‰å®ç° - é—®é¢˜ä»£ç 
if is_titan_stream:
    outputs = self.model(x_slice, use_state=False)  # âŒ å§‹ç»ˆä½¿ç”¨åˆå§‹è®°å¿†
```

**å½±å“**ï¼š
- è®­ç»ƒæ—¶æ¯ä¸ªæ ·æœ¬ç‹¬ç«‹ï¼Œæ— æ³•å­¦ä¹ "è®°å¿†å¦‚ä½•è·¨æ—¶é—´æ¼”åŒ–"
- æµ‹è¯•æ—¶è®°å¿†å»¶ç»­ï¼Œå¯¼è‡´**è®­ç»ƒ-æµ‹è¯•ä¸ä¸€è‡´**
- è¿™æ˜¯ RÂ² ä¸ºè´Ÿçš„ä¸»è¦åŸå› ä¹‹ä¸€

---

#### é—®é¢˜ 2ï¼šä¸€é˜¶æˆªæ–­å¯¼è‡´æ— æ³•å­¦ä¹ è®°å¿†æ›´æ–°ç­–ç•¥

**é—®é¢˜æè¿°**ï¼š
- è®¾è®¡è¦æ±‚ï¼šæ¢¯åº¦é€šè¿‡è®°å¿†æ›´æ–°åå‘ä¼ æ’­ï¼ˆGradient through Gradientï¼‰ï¼Œç±»ä¼¼å…ƒå­¦ä¹ 
- å®é™…å®ç°ï¼šé»˜è®¤ `use_high_order=False`ï¼Œæ¯ä¸ªæ—¶é—´ç‰‡å†…åå‘ä¼ æ’­åç«‹å³æˆªæ–­æ¢¯åº¦å›¾

**ä»£ç ä½ç½®**ï¼š`exp/exp_long_term_forecasting.py:250-258`
```python
# å½“å‰å®ç° - é—®é¢˜ä»£ç 
if (not use_high_order) and len(time_slices) > 1:
    backward_in_slices = True
    loss_total.backward()  # âŒ æˆªæ–­æ¢¯åº¦å›¾ï¼Œæ— æ³•å­¦ä¹ æ›´æ–°ç­–ç•¥
```

**å½±å“**ï¼š
- æ¨¡å‹åªå­¦åˆ°"ç»™å®šå›ºå®šè®°å¿†å¦‚ä½•é¢„æµ‹"
- æ— æ³•å­¦ä¹ "å¦‚ä½•é€šè¿‡æƒŠå¥‡åº¦åŠ¨æ€è°ƒæ•´è®°å¿†"
- é—¨æ§ç½‘ç»œ Gate æ— æ³•å­¦åˆ°æœ‰æ„ä¹‰çš„é—å¿˜ç­–ç•¥

---

#### é—®é¢˜ 3ï¼šè®°å¿†å¤ä½æ—¶æœºé”™è¯¯

**é—®é¢˜æè¿°**ï¼š
- è®¾è®¡è¦æ±‚ï¼šæ¯ä¸ªè®­ç»ƒæ ·æœ¬ï¼ˆbatchï¼‰å¼€å§‹æ—¶é‡ç½®è®°å¿†ï¼Œç„¶ååœ¨ Chunk å¾ªç¯ä¸­å»¶ç»­
- å®é™…å®ç°ï¼šæ¯ä¸ª epoch å¼€å§‹æ—¶é‡ç½®ä¸€æ¬¡ï¼Œæ•´ä¸ª epoch å†…è®°å¿†çŠ¶æ€æ··ä¹±

**ä»£ç ä½ç½®**ï¼š`exp/exp_long_term_forecasting.py:140-145`
```python
# å½“å‰å®ç° - é—®é¢˜ä»£ç 
for epoch in range(self.args.train_epochs):
    if hasattr(self.model, "reset_memory"):
        self.model.reset_memory()  # âŒ æ¯ä¸ª epoch é‡ç½®ä¸€æ¬¡
    for i, (batch_x, batch_y, ...) in enumerate(train_loader):
        # ... è®°å¿†çŠ¶æ€åœ¨ batch ä¹‹é—´æ··ä¹±å»¶ç»­
```

**å½±å“**ï¼š
- ä¸åŒæ ·æœ¬çš„è®°å¿†çŠ¶æ€ç›¸äº’æ±¡æŸ“
- æ— æ³•æ­£ç¡®æ¨¡æ‹Ÿ"æ¯ä¸ªåºåˆ—ä»é›¶å¼€å§‹çš„åœ¨çº¿æµ"

---

### ğŸŸ¡ P1 - åº”è¯¥æ”¹è¿›ï¼ˆå½±å“æ€§èƒ½ï¼‰

#### é—®é¢˜ 4ï¼šH_mem è®¡ç®—è¯­ä¹‰ä¸æ˜ç¡®

**é—®é¢˜æè¿°**ï¼š
- è®¾è®¡æ–‡æ¡£ï¼š`H_mem = M_{t-1} Â· Q_mem`ï¼ˆè®°å¿†ä½œä¸ºå˜æ¢çŸ©é˜µï¼‰
- Linear Attention æ ‡å‡†å½¢å¼ï¼š`Output = Q Â· M`ï¼ˆQuery å·¦ä¹˜è®°å¿†ï¼‰
- å½“å‰å®ç°ï¼š`H_mem = M Â· Q`ï¼ˆè®°å¿†å³ä¹˜ Queryï¼‰

**ä»£ç ä½ç½®**ï¼š`models/titan_stream.py:97`
```python
h_mem = torch.einsum("ij,bld->bld", mem_matrix, q)  # M Â· Q
```

**å½±å“**ï¼š
- è¯­ä¹‰ä¸Šæ˜¯"è®°å¿†ä½œä¸ºçº¿æ€§å˜æ¢"è€Œé"è®°å¿†ä½œä¸º KV ç¼“å­˜"
- å¯èƒ½ä¸æ˜¯æœ€ä¼˜çš„è®°å¿†æ£€ç´¢æ–¹å¼
- éœ€è¦æ˜ç¡®è®¾è®¡æ„å›¾

---

#### é—®é¢˜ 5ï¼šPersistent Memory å®Œå…¨å†»ç»“

**é—®é¢˜æè¿°**ï¼š
- è®¾è®¡è¦æ±‚ï¼š"åœ¨çº¿æµ‹è¯•é˜¶æ®µï¼Œé€šå¸¸å†»ç»“**æˆ–ä»…æ¥å—æä½å­¦ä¹ ç‡å¾®è°ƒ**"
- å®é™…å®ç°ï¼šå®Œå…¨å†»ç»“ï¼Œæ— å¾®è°ƒé€‰é¡¹

**ä»£ç ä½ç½®**ï¼š`exp/exp_online_forecast.py:128-131`
```python
if hasattr(self.model, 'freeze_backbone'):
    self.model.freeze_backbone()  # å®Œå…¨å†»ç»“
```

**å½±å“**ï¼š
- æ— æ³•é€‚åº”é•¿æœŸåˆ†å¸ƒæ¼‚ç§»
- Persistent Memory å­˜å‚¨çš„å…ˆéªŒå¯èƒ½è¿‡æ—¶

---

#### é—®é¢˜ 6ï¼šæ¢¯åº¦å½’ä¸€åŒ–é˜ˆå€¼è¿‡å¤§

**é—®é¢˜æè¿°**ï¼š
- å½“å‰é˜ˆå€¼ï¼š`grad_norm > 1e3` æ—¶æ‰å½’ä¸€åŒ–
- é—®é¢˜ï¼š1000 çš„æ¢¯åº¦èŒƒæ•°å·²ç»éå¸¸å¤§ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®š

**ä»£ç ä½ç½®**ï¼š`models/titan_stream.py:129-131`
```python
if torch.isfinite(grad_norm) and grad_norm > 1e3:
    self.momentum_state.mul_(1e3 / grad_norm)  # é˜ˆå€¼è¿‡å¤§
```

**å½±å“**ï¼š
- æ¢¯åº¦çˆ†ç‚¸é£é™©
- è®­ç»ƒä¸ç¨³å®š

---

### ğŸŸ¢ P2 - å¯é€‰ä¼˜åŒ–ï¼ˆé”¦ä¸Šæ·»èŠ±ï¼‰

#### é—®é¢˜ 7ï¼šCore Forecaster æ± åŒ–ç­–ç•¥ç®€å•

**é—®é¢˜æè¿°**ï¼š
- å½“å‰ï¼šç®€å•å¹³å‡æ± åŒ– `core_out.mean(dim=0)`
- å¯ä¼˜åŒ–ï¼šæ³¨æ„åŠ›æ± åŒ–æˆ–ä½¿ç”¨ç‰¹å®šä½ç½®çš„ token

**ä»£ç ä½ç½®**ï¼š`models/titan_stream.py:172`

---

#### é—®é¢˜ 8ï¼šæ­£äº¤æŸå¤±æœªå®é™…ä½¿ç”¨

**é—®é¢˜æè¿°**ï¼š
- ä»£ç ä¸­æœ‰ `loss_orth` å ä½ç¬¦
- ä½† TitanStream æ¨¡å‹æœªå®ç° `compute_orthogonal_loss()` æ–¹æ³•

**ä»£ç ä½ç½®**ï¼š`exp/exp_long_term_forecasting.py:240-241`

---

#### é—®é¢˜ 9ï¼šå»¶è¿Ÿåé¦ˆå›ºå®šå»¶è¿Ÿ

**é—®é¢˜æè¿°**ï¼š
- å½“å‰ï¼šå›ºå®šå»¶è¿Ÿ `pred_len` æ­¥
- çœŸå®åœºæ™¯ï¼šæ ‡ç­¾åˆ°è¾¾æ—¶é—´å¯èƒ½ä¸ç¡®å®š

---

## äºŒã€ä¿®å¤æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1ï¼šä¿®å¤ç¦»çº¿è®­ç»ƒçš„è®°å¿†å»¶ç»­ï¼ˆå¯¹åº”é—®é¢˜ 1ï¼‰

**ä¿®æ”¹æ–‡ä»¶**ï¼š`exp/exp_long_term_forecasting.py`

**ä¿®æ”¹å†…å®¹**ï¼š
```python
# åœ¨ Chunk å¾ªç¯ä¸­ï¼Œç¬¬ä¸€ä¸ª chunk ä½¿ç”¨åˆå§‹è®°å¿†ï¼Œåç»­ chunk å»¶ç»­çŠ¶æ€
for t, (t_start, t_end) in enumerate(time_slices):
    x_slice = sub_x[:, t_start:t_end]
    y_slice = sub_y[:, t_start:t_end]

    if is_titan_stream:
        # å…³é”®ä¿®æ”¹ï¼šç¬¬ä¸€ä¸ª chunk ä¸ä½¿ç”¨çŠ¶æ€ï¼ˆä½¿ç”¨ memory_initï¼‰
        # åç»­ chunk ä½¿ç”¨å¹¶æ›´æ–°çŠ¶æ€ï¼ˆæ¨¡æ‹Ÿåœ¨çº¿æµï¼‰
        use_state_for_chunk = (t > 0)
        update_state_for_chunk = True  # è®­ç»ƒæ—¶ä¹Ÿæ›´æ–°çŠ¶æ€
        outputs = self.model(
            x_slice,
            use_state=use_state_for_chunk,
            update_state=update_state_for_chunk
        )
```

**æ³¨æ„äº‹é¡¹**ï¼š
- éœ€è¦ç¡®ä¿ `update_state=True` æ—¶æ¢¯åº¦èƒ½æ­£ç¡®æµåŠ¨
- å½“å‰ `_update_online_memory` ä½¿ç”¨ `torch.no_grad()`ï¼Œéœ€è¦ä¿®æ”¹

---

### æ–¹æ¡ˆ 2ï¼šå®ç°äºŒé˜¶æ¢¯åº¦æ”¯æŒï¼ˆå¯¹åº”é—®é¢˜ 2ï¼‰

**ä¿®æ”¹æ–‡ä»¶**ï¼š`models/titan_stream.py`

**ä¿®æ”¹å†…å®¹**ï¼š

1. æ·»åŠ å¯å¾®åˆ†çš„è®°å¿†æ›´æ–°æ–¹æ³•ï¼š
```python
def _update_memory_differentiable(self, grad_mem, gate_value):
    """
    å¯å¾®åˆ†çš„è®°å¿†æ›´æ–°ï¼ˆç”¨äºè®­ç»ƒæ—¶çš„äºŒé˜¶æ¢¯åº¦ï¼‰
    """
    # åŠ¨é‡æ›´æ–°ï¼ˆä¿ç•™æ¢¯åº¦ï¼‰
    new_momentum = self.beta_momentum * self.momentum_state + (1 - self.beta_momentum) * grad_mem

    # é—¨æ§æ›´æ–°ï¼ˆä¿ç•™æ¢¯åº¦ï¼‰
    new_memory = (1 - gate_value) * self.memory_state - self.lr_memory * new_momentum

    return new_memory, new_momentum
```

2. ä¿®æ”¹ forward æ–¹æ³•æ”¯æŒå¯å¾®åˆ†æ›´æ–°ï¼š
```python
def forward(self, x_enc, ..., use_state=False, update_state=False, differentiable_update=False):
    # ... ç°æœ‰ä»£ç  ...

    if update_state:
        if differentiable_update:
            # å¯å¾®åˆ†æ›´æ–°ï¼ˆè®­ç»ƒæ—¶ä½¿ç”¨ï¼‰
            self.memory_state, self.momentum_state = self._update_memory_differentiable(
                grad_mem, gate_value
            )
        else:
            # åŸåœ°æ›´æ–°ï¼ˆæ¨ç†æ—¶ä½¿ç”¨ï¼Œæ— æ¢¯åº¦ï¼‰
            self._update_online_memory(grad_mem.detach(), gate_value.detach())
```

---

### æ–¹æ¡ˆ 3ï¼šä¿®å¤è®°å¿†å¤ä½æ—¶æœºï¼ˆå¯¹åº”é—®é¢˜ 3ï¼‰

**ä¿®æ”¹æ–‡ä»¶**ï¼š`exp/exp_long_term_forecasting.py`

**ä¿®æ”¹å†…å®¹**ï¼š
```python
for epoch in range(self.args.train_epochs):
    # ç§»é™¤è¿™é‡Œçš„ reset_memory
    # if hasattr(self.model, "reset_memory"):
    #     self.model.reset_memory()

    for i, (batch_x, batch_y, ...) in enumerate(train_loader):
        # æ¯ä¸ª batch å¼€å§‹æ—¶é‡ç½®è®°å¿†
        if is_titan_stream and hasattr(self.model, "reset_memory"):
            self.model.reset_memory()

        # ... åç»­ chunk å¾ªç¯ä¸­è®°å¿†å»¶ç»­ ...
```

---

### æ–¹æ¡ˆ 4ï¼šæ˜ç¡® H_mem è®¡ç®—è¯­ä¹‰ï¼ˆå¯¹åº”é—®é¢˜ 4ï¼‰

**é€‰é¡¹ A**ï¼šä¿æŒå½“å‰å®ç°ï¼Œæ›´æ–°è®¾è®¡æ–‡æ¡£
- å½“å‰ `H_mem = M Â· Q` çš„è¯­ä¹‰æ˜¯"è®°å¿†ä½œä¸ºçº¿æ€§å˜æ¢çŸ©é˜µ"
- åœ¨è®¾è®¡æ–‡æ¡£ä¸­æ˜ç¡®è¯´æ˜è¿™ä¸ªé€‰æ‹©

**é€‰é¡¹ B**ï¼šæ”¹ä¸ºæ ‡å‡† Linear Attention å½¢å¼
```python
# ä¿®æ”¹ models/titan_stream.py:97
h_mem = torch.einsum("bld,df->blf", q, mem_matrix)  # Q Â· M
```

**å»ºè®®**ï¼šå…ˆä¿æŒå½“å‰å®ç°ï¼ˆé€‰é¡¹ Aï¼‰ï¼Œåœ¨æ¶ˆèå®éªŒä¸­å¯¹æ¯”ä¸¤ç§æ–¹å¼

---

### æ–¹æ¡ˆ 5ï¼šæ·»åŠ  Persistent Memory åœ¨çº¿å¾®è°ƒï¼ˆå¯¹åº”é—®é¢˜ 5ï¼‰

**ä¿®æ”¹æ–‡ä»¶**ï¼š`models/titan_stream.py` å’Œ `exp/exp_online_forecast.py`

**ä¿®æ”¹å†…å®¹**ï¼š

1. åœ¨ TitanStream ä¸­æ·»åŠ æ–¹æ³•ï¼š
```python
def get_persistent_params(self):
    """è¿”å› Persistent Memory å‚æ•°"""
    return [self.persistent_k, self.persistent_v]

def freeze_persistent(self):
    """å†»ç»“ Persistent Memory"""
    self.persistent_k.requires_grad = False
    self.persistent_v.requires_grad = False

def unfreeze_persistent(self, lr_scale=0.01):
    """è§£å†» Persistent Memoryï¼ˆç”¨äºæä½å­¦ä¹ ç‡å¾®è°ƒï¼‰"""
    self.persistent_k.requires_grad = True
    self.persistent_v.requires_grad = True
    return lr_scale  # è¿”å›å»ºè®®çš„å­¦ä¹ ç‡ç¼©æ”¾å› å­
```

2. åœ¨ exp_online_forecast.py ä¸­æ·»åŠ é…ç½®ï¼š
```python
self.persistent_lr_scale = getattr(args, 'persistent_lr_scale', 0.0)  # 0 è¡¨ç¤ºå†»ç»“
```

---

### æ–¹æ¡ˆ 6ï¼šé™ä½æ¢¯åº¦å½’ä¸€åŒ–é˜ˆå€¼ï¼ˆå¯¹åº”é—®é¢˜ 6ï¼‰

**ä¿®æ”¹æ–‡ä»¶**ï¼š`models/titan_stream.py`

**ä¿®æ”¹å†…å®¹**ï¼š
```python
def _update_online_memory(self, grad_mem, gate_value):
    with torch.no_grad():
        self.momentum_state.mul_(self.beta_momentum).add_(grad_mem, alpha=1 - self.beta_momentum)

        # ä¿®æ”¹ï¼šé™ä½é˜ˆå€¼ï¼Œå¢åŠ ç¨³å®šæ€§
        grad_norm = torch.norm(self.momentum_state)
        max_grad_norm = 10.0  # ä» 1e3 é™ä½åˆ° 10
        if torch.isfinite(grad_norm) and grad_norm > max_grad_norm:
            self.momentum_state.mul_(max_grad_norm / grad_norm)

        self.memory_state.mul_(1 - gate_value).add_(self.momentum_state, alpha=-self.lr_memory)
```

---

### æ–¹æ¡ˆ 7-9ï¼šP2 ä¼˜åŒ–ï¼ˆåç»­å®æ–½ï¼‰

è¿™äº›ä¼˜åŒ–åœ¨ P0/P1 é—®é¢˜ä¿®å¤å¹¶éªŒè¯åå†å®æ–½ã€‚

---

## ä¸‰ã€å®æ–½è®¡åˆ’

### é˜¶æ®µ 1ï¼šæ ¸å¿ƒä¿®å¤ï¼ˆP0 é—®é¢˜ï¼‰

| åºå· | ä»»åŠ¡ | ä¿®æ”¹æ–‡ä»¶ | é¢„è®¡å½±å“ | çŠ¶æ€ |
|------|------|----------|----------|------|
| 1.1 | ä¿®å¤è®°å¿†å¤ä½æ—¶æœº | exp_long_term_forecasting.py | ä½é£é™© | âœ… å·²å®Œæˆ |
| 1.2 | æ·»åŠ å¯å¾®åˆ†è®°å¿†æ›´æ–° | models/titan_stream.py | ä¸­é£é™© | âœ… å·²å®Œæˆ |
| 1.3 | ä¿®å¤è®­ç»ƒæ—¶è®°å¿†å»¶ç»­ | exp_long_term_forecasting.py | ä¸­é£é™© | âœ… å·²å®Œæˆ |
| 1.4 | éªŒè¯è®­ç»ƒ-æµ‹è¯•ä¸€è‡´æ€§ | - | - | â³ å¾…å®æ–½ |

### é˜¶æ®µ 2ï¼šæ€§èƒ½æ”¹è¿›ï¼ˆP1 é—®é¢˜ï¼‰

| åºå· | ä»»åŠ¡ | ä¿®æ”¹æ–‡ä»¶ | é¢„è®¡å½±å“ | çŠ¶æ€ |
|------|------|----------|----------|------|
| 2.1 | é™ä½æ¢¯åº¦å½’ä¸€åŒ–é˜ˆå€¼ | models/titan_stream.py | ä½é£é™© | âœ… å·²å®Œæˆ |
| 2.2 | æ·»åŠ  Persistent Memory å¾®è°ƒé€‰é¡¹ | titan_stream.py, run.py | ä½é£é™© | âœ… å·²å®Œæˆ |
| 2.3 | æ˜ç¡® H_mem è¯­ä¹‰ï¼ˆæ›´æ–°æ–‡æ¡£ï¼‰ | FSMdesign.md | ä½é£é™© | âœ… å·²å®Œæˆ |

### é˜¶æ®µ 3ï¼šå¯é€‰ä¼˜åŒ–ï¼ˆP2 é—®é¢˜ï¼‰

| åºå· | ä»»åŠ¡ | ä¿®æ”¹æ–‡ä»¶ | é¢„è®¡å½±å“ | çŠ¶æ€ |
|------|------|----------|----------|------|
| 3.1 | ä¼˜åŒ– Core Forecaster æ± åŒ– | models/titan_stream.py | ä½é£é™© | â³ å¾…å®æ–½ |
| 3.2 | å®ç°æ­£äº¤æŸå¤± | models/titan_stream.py | ä½é£é™© | â³ å¾…å®æ–½ |
| 3.3 | æ”¯æŒå¯å˜å»¶è¿Ÿåé¦ˆ | utils/online_utils.py | ä½é£é™© | â³ å¾…å®æ–½ |

### é˜¶æ®µ 4ï¼šéªŒè¯ä¸æ¶ˆè

| åºå· | ä»»åŠ¡ | è¯´æ˜ | çŠ¶æ€ |
|------|------|------|------|
| 4.1 | å°æ•°æ®é›†éªŒè¯ | ETTh1, seq_len=96, pred_len=24 | â³ å¾…å®æ–½ |
| 4.2 | è®­ç»ƒ-æµ‹è¯•ä¸€è‡´æ€§æ£€æŸ¥ | å¯¹æ¯”ä¿®å¤å‰åçš„ RÂ² | â³ å¾…å®æ–½ |
| 4.3 | æ¶ˆèå®éªŒ | beta, eta, n_persistent, use_high_order | â³ å¾…å®æ–½ |

---

## å››ã€å®æ–½é¡ºåº

```
1.1 ä¿®å¤è®°å¿†å¤ä½æ—¶æœº
    â†“
1.2 æ·»åŠ å¯å¾®åˆ†è®°å¿†æ›´æ–°
    â†“
1.3 ä¿®å¤è®­ç»ƒæ—¶è®°å¿†å»¶ç»­
    â†“
1.4 éªŒè¯è®­ç»ƒ-æµ‹è¯•ä¸€è‡´æ€§
    â†“
2.1 é™ä½æ¢¯åº¦å½’ä¸€åŒ–é˜ˆå€¼
    â†“
2.2 æ·»åŠ  Persistent Memory å¾®è°ƒé€‰é¡¹
    â†“
2.3 æ˜ç¡® H_mem è¯­ä¹‰
    â†“
4.1-4.3 éªŒè¯ä¸æ¶ˆè
    â†“
3.1-3.3 å¯é€‰ä¼˜åŒ–ï¼ˆæ ¹æ®æ¶ˆèç»“æœå†³å®šï¼‰
```

---

## äº”ã€é£é™©è¯„ä¼°

### é«˜é£é™©æ“ä½œ
- **1.2 å¯å¾®åˆ†è®°å¿†æ›´æ–°**ï¼šæ¶‰åŠæ¢¯åº¦å›¾çš„ä¿ç•™ï¼Œå¯èƒ½å¯¼è‡´æ˜¾å­˜çˆ†ç‚¸
  - ç¼“è§£æªæ–½ï¼šé™åˆ¶ chunk_lenï¼Œä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹

### ä¸­é£é™©æ“ä½œ
- **1.3 è®­ç»ƒæ—¶è®°å¿†å»¶ç»­**ï¼šæ”¹å˜è®­ç»ƒè¡Œä¸ºï¼Œå¯èƒ½éœ€è¦é‡æ–°è°ƒå‚
  - ç¼“è§£æªæ–½ï¼šå…ˆåœ¨å°æ•°æ®é›†éªŒè¯ï¼Œä¿ç•™æ—§ä»£ç ä½œä¸º fallback

### ä½é£é™©æ“ä½œ
- å…¶ä»–ä¿®æ”¹å‡ä¸ºå±€éƒ¨æ”¹åŠ¨ï¼Œå½±å“èŒƒå›´å¯æ§

---

## å…­ã€å›æ»šæ–¹æ¡ˆ

æ¯ä¸ªä¿®æ”¹éƒ½åº”è¯¥ï¼š
1. é€šè¿‡é…ç½®å¼€å…³æ§åˆ¶ï¼ˆå¦‚ `use_differentiable_update`ï¼‰
2. ä¿ç•™åŸæœ‰ä»£ç è·¯å¾„
3. åœ¨éªŒè¯å¤±è´¥æ—¶å¯å¿«é€Ÿå›æ»š

---

## ä¸ƒã€æ–‡æ¡£æ›´æ–°

ä¿®å¤å®Œæˆåéœ€è¦æ›´æ–°ï¼š
1. `FSMdesign.md` - è¡¥å……å®ç°ç»†èŠ‚è¯´æ˜
2. `TITAN_STREAM_REFACTOR_PLAN.md` - æ›´æ–°è¿›åº¦çŠ¶æ€
3. `README.md` - æ·»åŠ ä½¿ç”¨è¯´æ˜

---

## å…«ã€å®æ–½æ€»ç»“ï¼ˆ2025-12-11ï¼‰

### å·²å®Œæˆçš„ä¿®å¤

#### P0 æ ¸å¿ƒä¿®å¤ï¼ˆ3/3 å®Œæˆï¼‰

1. **âœ… ä¿®å¤è®°å¿†å¤ä½æ—¶æœºï¼ˆé—®é¢˜ 1.1ï¼‰**
   - ä¿®æ”¹ä½ç½®ï¼š`exp/exp_long_term_forecasting.py:138-149`
   - æ”¹åŠ¨ï¼šå°†è®°å¿†å¤ä½ä» epoch çº§åˆ«ç§»åˆ° batch çº§åˆ«
   - å½±å“ï¼šæ¯ä¸ªè®­ç»ƒæ ·æœ¬ç°åœ¨ä»ç‹¬ç«‹çš„åˆå§‹è®°å¿†å¼€å§‹ï¼Œæ­£ç¡®æ¨¡æ‹Ÿåœ¨çº¿æµ

2. **âœ… æ·»åŠ å¯å¾®åˆ†è®°å¿†æ›´æ–°ï¼ˆé—®é¢˜ 1.2ï¼‰**
   - ä¿®æ”¹ä½ç½®ï¼š`models/titan_stream.py:120-149, 167-245`
   - æ–°å¢æ–¹æ³•ï¼š`_update_memory_differentiable()`
   - æ–°å¢å‚æ•°ï¼š`differentiable_update` æ ‡å¿—
   - å½±å“ï¼šæ”¯æŒäºŒé˜¶æ¢¯åº¦ï¼Œå…è®¸æ¢¯åº¦é€šè¿‡è®°å¿†æ›´æ–°åå‘ä¼ æ’­

3. **âœ… ä¿®å¤è®­ç»ƒæ—¶è®°å¿†å»¶ç»­ï¼ˆé—®é¢˜ 1.3ï¼‰**
   - ä¿®æ”¹ä½ç½®ï¼š`exp/exp_long_term_forecasting.py:202-276`
   - æ”¹åŠ¨ï¼šåœ¨ time_slices å¾ªç¯ä¸­å»¶ç»­è®°å¿†çŠ¶æ€
   - é€»è¾‘ï¼šç¬¬ä¸€ä¸ª chunk ä½¿ç”¨åˆå§‹è®°å¿†ï¼Œåç»­ chunk å»¶ç»­çŠ¶æ€
   - å½±å“ï¼šè®­ç»ƒæ—¶æ­£ç¡®æ¨¡æ‹Ÿåœ¨çº¿æµçš„è¿ç»­æ€§

#### P1 æ€§èƒ½æ”¹è¿›ï¼ˆ3/3 å®Œæˆï¼‰

4. **âœ… é™ä½æ¢¯åº¦å½’ä¸€åŒ–é˜ˆå€¼ï¼ˆé—®é¢˜ 2.1ï¼‰**
   - ä¿®æ”¹ä½ç½®ï¼š`models/titan_stream.py:139, 161`
   - æ”¹åŠ¨ï¼šé˜ˆå€¼ä» 1e3 é™ä½åˆ° 10.0
   - å½±å“ï¼šæé«˜è®­ç»ƒç¨³å®šæ€§ï¼Œå‡å°‘æ¢¯åº¦çˆ†ç‚¸é£é™©

5. **âœ… æ·»åŠ  Persistent Memory å¾®è°ƒé€‰é¡¹ï¼ˆé—®é¢˜ 2.2ï¼‰**
   - ä¿®æ”¹ä½ç½®ï¼š`models/titan_stream.py:83-95`, `run.py:116`
   - æ–°å¢æ–¹æ³•ï¼š`get_persistent_params()`, `freeze_persistent()`, `unfreeze_persistent()`
   - æ–°å¢å‚æ•°ï¼š`--persistent_lr_scale`
   - å½±å“ï¼šæ”¯æŒåœ¨çº¿æµ‹è¯•æ—¶å¯¹ Persistent Memory è¿›è¡Œæä½å­¦ä¹ ç‡å¾®è°ƒ

6. **âœ… æ˜ç¡® H_mem è¯­ä¹‰ï¼ˆé—®é¢˜ 2.3ï¼‰**
   - ä¿®æ”¹ä½ç½®ï¼š`FSMdesign.md:35-39`
   - æ”¹åŠ¨ï¼šåœ¨è®¾è®¡æ–‡æ¡£ä¸­æ˜ç¡®è¯´æ˜ `H_mem = M Â· Q` çš„è¯­ä¹‰
   - è¯´æ˜ï¼šè®°å¿†ä½œä¸ºçº¿æ€§å˜æ¢çŸ©é˜µï¼Œè€Œéé”®å€¼ç¼“å­˜
   - å½±å“ï¼šè®¾è®¡æ„å›¾æ¸…æ™°ï¼Œä¾¿äºåç»­æ¶ˆèå®éªŒ

### å…³é”®æ”¹è¿›ç‚¹

1. **è®­ç»ƒ-æµ‹è¯•ä¸€è‡´æ€§**ï¼šä¿®å¤åï¼Œè®­ç»ƒæ—¶ä¹Ÿæ¨¡æ‹Ÿåœ¨çº¿æµï¼Œè®°å¿†çŠ¶æ€åœ¨ chunk ä¹‹é—´å»¶ç»­
2. **å…ƒå­¦ä¹ æ”¯æŒ**ï¼šå¯å¾®åˆ†æ›´æ–°å…è®¸æ¨¡å‹å­¦ä¹ "å¦‚ä½•æ›´æ–°è®°å¿†"
3. **æ•°å€¼ç¨³å®šæ€§**ï¼šé™ä½æ¢¯åº¦å½’ä¸€åŒ–é˜ˆå€¼ï¼Œå‡å°‘è®­ç»ƒä¸ç¨³å®š
4. **çµæ´»æ€§**ï¼šæ”¯æŒ Persistent Memory å¾®è°ƒï¼Œé€‚åº”é•¿æœŸåˆ†å¸ƒæ¼‚ç§»

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **éªŒè¯ä¿®å¤æ•ˆæœ**ï¼š
   - åœ¨å°æ•°æ®é›†ï¼ˆETTh1, seq_len=96, pred_len=24ï¼‰ä¸Šè®­ç»ƒ
   - å¯¹æ¯”ä¿®å¤å‰åçš„ RÂ² æŒ‡æ ‡
   - æ£€æŸ¥è®­ç»ƒ-æµ‹è¯•ä¸€è‡´æ€§

2. **å¯ç”¨é«˜é˜¶æ¢¯åº¦è®­ç»ƒ**ï¼š
   - è®¾ç½® `--use_high_order` æ ‡å¿—
   - ç›‘æ§æ˜¾å­˜ä½¿ç”¨å’Œè®­ç»ƒæ—¶é—´
   - è¯„ä¼°äºŒé˜¶æ¢¯åº¦å¯¹æ€§èƒ½çš„å½±å“

3. **æ¶ˆèå®éªŒ**ï¼š
   - å¯¹æ¯” `use_high_order=True/False`
   - å¯¹æ¯”ä¸åŒçš„ `beta_momentum`, `lr_memory`, `n_persistent`
   - è¯„ä¼° Persistent Memory å¾®è°ƒçš„æ•ˆæœ

### é¢„æœŸæ•ˆæœ

- **RÂ² æŒ‡æ ‡**ï¼šä»è´Ÿå€¼æå‡åˆ°æ­£å€¼ï¼ˆé¢„æœŸ > 0.5ï¼‰
- **è®­ç»ƒç¨³å®šæ€§**ï¼šæ¢¯åº¦ä¸å†çˆ†ç‚¸ï¼Œloss å¹³æ»‘ä¸‹é™
- **åœ¨çº¿é€‚åº”èƒ½åŠ›**ï¼šæ¨¡å‹èƒ½å¤Ÿæ­£ç¡®åˆ©ç”¨å»¶è¿Ÿåé¦ˆè¿›è¡Œåœ¨çº¿æ›´æ–°

---

*æ–‡æ¡£åˆ›å»ºæ—¶é—´ï¼š2025-12-11*
*æœ€åæ›´æ–°ï¼š2025-12-11 - å®Œæˆ P0/P1 ä¿®å¤*

---

## ğŸ”´ é—®é¢˜ 7ï¼šè®¡ç®—å›¾ç´¯ç§¯å¯¼è‡´æ˜¾å­˜æ³„éœ²å’Œé€Ÿåº¦ä¸‹é™ï¼ˆæ–°å‘ç° - P0ï¼‰

**å‘ç°æ—¶é—´**ï¼š2025-12-11

**é—®é¢˜æè¿°**ï¼š
- åœ¨è®­ç»ƒæ—¶ï¼Œ`temp_memory` å’Œ `temp_momentum` åœ¨ time_slices ä¹‹é—´ä¼ é€’æ—¶æ²¡æœ‰ `.detach()`
- å¯¼è‡´è®¡ç®—å›¾è·¨ slice ç´¯ç§¯ï¼Œæ¯ä¸ª epoch é€Ÿåº¦æŒ‡æ•°çº§ä¸‹é™

**ä»£ç ä½ç½®**ï¼š`exp/exp_long_term_forecasting.py:271-273`
```python
# é—®é¢˜ä»£ç 
if stats.get('updated_memory') is not None:
    temp_memory = stats['updated_memory']  # âŒ æ²¡æœ‰ detach()
if stats.get('updated_momentum') is not None:
    temp_momentum = stats['updated_momentum']  # âŒ æ²¡æœ‰ detach()
```

**å½±å“**ï¼š
- **æ˜¾å­˜çˆ†ç‚¸**ï¼šè®¡ç®—å›¾åœ¨ batch å†…è·¨ slice ç´¯ç§¯
- **é€Ÿåº¦æŒ‡æ•°çº§ä¸‹é™**ï¼šEpoch 1 (0.26s/iter) â†’ Epoch 6 (3.7s/iter)
- **æœ€ç»ˆ OOM**ï¼šæ˜¾å­˜è€—å°½å¯¼è‡´è®­ç»ƒå´©æºƒ

**ç—‡çŠ¶**ï¼š
- éšç€ epoch å¢åŠ ï¼Œæ¯ä¸ª epoch è€—æ—¶è¶Šæ¥è¶Šé•¿
- æ˜¾å­˜å ç”¨æŒç»­å¢é•¿
- åå‘ä¼ æ’­æ—¶é—´æ˜¾è‘—å¢åŠ 

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
# ä¿®å¤ä»£ç 
if stats.get('updated_memory') is not None:
    temp_memory = stats['updated_memory'].detach()  # âœ… æˆªæ–­è®¡ç®—å›¾
if stats.get('updated_momentum') is not None:
    temp_momentum = stats['updated_momentum'].detach()  # âœ… æˆªæ–­è®¡ç®—å›¾
```

**é¢å¤–ä¼˜åŒ–**ï¼š
```python
# åœ¨æ¯ä¸ª batch ç»“æŸåæ¸…ç†ä¸­é—´å˜é‡
del loss, loss_chunks, loss_pred_vals, loss_proxy_vals, loss_orth_vals
if torch.cuda.is_available():
    torch.cuda.empty_cache()
```

**çŠ¶æ€**ï¼šâœ… å·²ä¿®å¤ï¼ˆ2025-12-11ï¼‰

---
