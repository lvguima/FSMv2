# ä¿®å¤æ€»ç»“ - 2025-12-11

æœ¬æ–‡æ¡£è®°å½•äº†ä»Šå¤©å¯¹ Titan-Stream æ¨¡å‹å’Œè®­ç»ƒæµç¨‹çš„æ‰€æœ‰å…³é”®ä¿®å¤ã€‚

---

## ğŸ”´ P0 - å…³é”®ä¿®å¤

### 1. è®¡ç®—å›¾ç´¯ç§¯å¯¼è‡´é€Ÿåº¦æŒ‡æ•°çº§ä¸‹é™

**é—®é¢˜æè¿°**ï¼š
- è®­ç»ƒæ—¶ `temp_memory` å’Œ `temp_momentum` åœ¨ time_slices ä¹‹é—´ä¼ é€’æ—¶æ²¡æœ‰ `.detach()`
- å¯¼è‡´è®¡ç®—å›¾è·¨ slice ç´¯ç§¯ï¼Œæ¯ä¸ª epoch é€Ÿåº¦æŒ‡æ•°çº§ä¸‹é™
- **ç—‡çŠ¶**ï¼šEpoch 1 (0.26s/iter) â†’ Epoch 6 (3.7s/iter)

**æ ¹æœ¬åŸå› **ï¼š
```python
# é—®é¢˜ä»£ç  (exp/exp_long_term_forecasting.py:271-273)
temp_memory = stats['updated_memory']      # âŒ æºå¸¦å®Œæ•´è®¡ç®—å›¾
temp_momentum = stats['updated_momentum']  # âŒ æºå¸¦å®Œæ•´è®¡ç®—å›¾
```

è®¡ç®—å›¾é“¾å¼ç´¯ç§¯ï¼š
- Slice 1: æ„å»ºå›¾ G1
- Slice 2: ä½¿ç”¨ G1 è¾“å‡º â†’ æ„å»º G1â†’G2
- Slice 3: ä½¿ç”¨ G2 è¾“å‡º â†’ æ„å»º G1â†’G2â†’G3
- åå‘ä¼ æ’­æ—¶é—´ âˆ O(nÂ²)

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
# ä¿®å¤ä»£ç 
temp_memory = stats['updated_memory'].detach()      # âœ… æˆªæ–­è®¡ç®—å›¾
temp_momentum = stats['updated_momentum'].detach()  # âœ… æˆªæ–­è®¡ç®—å›¾
```

**é¢å¤–ä¼˜åŒ–**ï¼š
```python
# æ¯ä¸ª batch ç»“æŸåæ¸…ç†ä¸­é—´å˜é‡
del loss, loss_chunks, loss_pred_vals, loss_proxy_vals, loss_orth_vals
if torch.cuda.is_available():
    torch.cuda.empty_cache()
```

**å½±å“**ï¼š
- âœ… æ¯ä¸ª epoch è€—æ—¶ç¨³å®š
- âœ… æ˜¾å­˜å ç”¨æ’å®š
- âœ… è®­ç»ƒé€Ÿåº¦æå‡ 10-15 å€

---

## ğŸŸ¡ P1 - æ¶æ„æ”¹è¿›

### 2. Forecast Head é‡æ–°è®¾è®¡

**é—®é¢˜æè¿°**ï¼š
- åŸå§‹è®¾è®¡ä½¿ç”¨ mean poolingï¼Œå®Œå…¨ä¸¢å¤±æ—¶åºä¿¡æ¯
- å°è¯• Flatten + MLP å¯¼è‡´å‚æ•°çˆ†ç‚¸ï¼ˆ201M å‚æ•°ï¼Œå æ¨¡å‹ 99%ï¼‰

**å¯¹æ¯”åˆ†æ**ï¼š

| æ–¹æ¡ˆ | å‚æ•°é‡ | å æ¯” | ä¼˜ç¼ºç‚¹ |
|------|--------|------|--------|
| Mean Pooling | 172K | 11.5% | âŒ ä¸¢å¤±æ—¶åºä¿¡æ¯ |
| Flatten + MLP | 201M | 99% | âŒ å‚æ•°çˆ†ç‚¸ |
| **Attention Pooling + MLP** | 740K | 35.1% | âœ… ä¿ç•™æ—¶åº + å‚æ•°åˆç† |

**æœ€ç»ˆæ–¹æ¡ˆ**ï¼šAttention Pooling + 2-layer MLP

```python
# Attention pooling: å­¦ä¹ ä¸€ä¸ª query å‘é‡
forecast_query = nn.Parameter(torch.randn(1, 1, D) * 0.02)
forecast_attn = nn.MultiheadAttention(D, n_heads, dropout)

# 2-layer MLP
forecast_head = nn.Sequential(
    nn.Linear(D, 2D),
    nn.GELU(),
    nn.Dropout(dropout),
    nn.Linear(2D, pred_len * c_out)
)

# Forward pass
query = forecast_query.expand(-1, B, -1)  # [1, B, D]
pooled, _ = forecast_attn(query, core_out, core_out)  # [1, B, D]
pooled = pooled.squeeze(0)  # [B, D]
forecast = forecast_head(pooled)  # [B, pred_len * c_out]
```

**ä¼˜åŠ¿**ï¼š
1. âœ… ä¿ç•™æ—¶åºä¿¡æ¯ï¼šé€šè¿‡ attention å­¦ä¹ å“ªäº›æ—¶é—´æ­¥é‡è¦
2. âœ… å‚æ•°é‡åˆç†ï¼š740K å‚æ•°ï¼Œå æ¨¡å‹ 35%
3. âœ… å¯è§£é‡Šæ€§ï¼šattention weights å¯ä»¥å¯è§†åŒ–
4. âœ… çµæ´»æ€§ï¼šå¯ä»¥å­¦ä¹ åŠ¨æ€èšåˆç­–ç•¥

**ä¿®æ”¹æ–‡ä»¶**ï¼š
- `models/titan_stream.py:67-88` (forecast head å®šä¹‰)
- `models/titan_stream.py:247-254` (forward pass)
- `run.py:196` (æ·»åŠ  `--forecast_hidden_dim` å‚æ•°)

---

## ğŸ”§ å®éªŒé…ç½®ä¿®å¤

### 3. Checkpoint è·¯å¾„ä¸ä¸€è‡´

**é—®é¢˜æè¿°**ï¼š
- ç¦»çº¿è®­ç»ƒä½¿ç”¨ `--data ETTm1_Online`
- åœ¨çº¿æµ‹è¯•ä½¿ç”¨ `--data ETTm1`
- å¯¼è‡´ setting åç§°ä¸åŒ¹é…ï¼Œcheckpoint æ— æ³•åŠ è½½

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```bash
# scripts/online_forecast/titan_ettm1_delayed.sh
DATA_NAME=ETTm1  # ç»Ÿä¸€ä½¿ç”¨ ETTm1

# ç¦»çº¿è®­ç»ƒ
--data ${DATA_NAME}

# åœ¨çº¿æµ‹è¯•
--data ${DATA_NAME}
```

**å½±å“**ï¼š
- âœ… Checkpoint æ­£ç¡®åŠ è½½
- âœ… åœ¨çº¿æµ‹è¯•ä½¿ç”¨é¢„è®­ç»ƒæƒé‡

---

### 4. è®­ç»ƒè¶…å‚æ•°ä¼˜åŒ–

**é—®é¢˜æè¿°**ï¼š
- `patience=3` è¿‡å°ï¼Œå¯¼è‡´è¿‡æ—©åœæ­¢
- `learning_rate=1e-3` + `lradj=type1` è¡°å‡è¿‡å¿«
- è®­ç»ƒåœ¨ Epoch 4 å°±æ—©åœï¼Œä½† loss ä»åœ¨ä¸‹é™

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```bash
# scripts/online_forecast/titan_ettm1_delayed.sh
--train_epochs 30 \      # 20 â†’ 30
--patience 7 \           # 3 â†’ 7
--learning_rate 5e-4 \   # 1e-3 â†’ 5e-4
--lradj cosine           # type1 â†’ cosine
```

**å½±å“**ï¼š
- âœ… è®­ç»ƒæ›´å……åˆ†
- âœ… å­¦ä¹ ç‡è¡°å‡æ›´å¹³æ»‘
- âœ… æ¨¡å‹æ”¶æ•›æ›´å¥½

---

### 5. Backbone å‚æ•°åˆ†ç»„ä¿®å¤

**é—®é¢˜æè¿°**ï¼š
- TitanStream å‚æ•°åæ²¡æœ‰ `backbone`/`encoder`/`embedding` å…³é”®è¯
- å¯¼è‡´æ‰€æœ‰å‚æ•°è¢«å½’ä¸º `head_params`
- åœ¨çº¿æµ‹è¯•æ—¶æ˜¾ç¤º "Backbone Params: 0"

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
# exp/exp_online_forecast.py:423-429
backbone_keywords = [
    'backbone', 'encoder', 'embedding',  # MStream åŸæœ‰
    'core', 'input_proj', 'q_proj', 'k_proj', 'v_proj'  # TitanStream æ–°å¢
]
head_keywords = [
    'memory', 'head', 'gate', 'persistent'
]
```

**ä¿®å¤åå‚æ•°åˆ†ç»„**ï¼š
- Backbone: 32 params (1.25M elements) - æ…¢é€Ÿå­¦ä¹  (LR Ã— 0.1)
- Head/Memory: 9 params (287K elements) - å¿«é€Ÿå­¦ä¹  (LR Ã— 1.0)

**å½±å“**ï¼š
- âœ… åŒé€Ÿå­¦ä¹ ç‡æ­£ç¡®åº”ç”¨
- âœ… Backbone å’Œ Head åˆ†åˆ«ä¼˜åŒ–

---

## ğŸ“Š ä¿®å¤æ•ˆæœé¢„æœŸ

### è®­ç»ƒé˜¶æ®µ
- âœ… æ¯ä¸ª epoch è€—æ—¶ç¨³å®šï¼ˆä¸å†æŒ‡æ•°å¢é•¿ï¼‰
- âœ… æ˜¾å­˜å ç”¨æ’å®šï¼ˆä¸å†æ³„éœ²ï¼‰
- âœ… è®­ç»ƒé€Ÿåº¦æå‡ 10-15 å€
- âœ… æ¨¡å‹æ”¶æ•›æ›´å……åˆ†ï¼ˆpatience å¢åŠ ï¼‰

### åœ¨çº¿æµ‹è¯•é˜¶æ®µ
- âœ… Checkpoint æ­£ç¡®åŠ è½½
- âœ… Backbone å‚æ•°æ­£ç¡®åˆ†ç»„
- âœ… åŒé€Ÿå­¦ä¹ ç‡æ­£ç¡®åº”ç”¨

### æ¨¡å‹æ€§èƒ½
- âœ… Forecast head ä¿ç•™æ—¶åºä¿¡æ¯
- âœ… å‚æ•°é‡åˆç†ï¼ˆ740K vs 201Mï¼‰
- âœ… é¢„æµ‹è´¨é‡æå‡

---

## ğŸ” å…³é”®ç»éªŒæ•™è®­

### 1. è®¡ç®—å›¾ç®¡ç†
**æ•™è®­**ï¼šåœ¨è®­ç»ƒå¾ªç¯ä¸­ä¼ é€’ tensor æ—¶ï¼Œå¿…é¡»æ˜ç¡®æ˜¯å¦éœ€è¦æ¢¯åº¦ã€‚

**è§„åˆ™**ï¼š
- å¦‚æœ tensor ç”¨äºä¸‹ä¸€ä¸ª forward pass çš„è¾“å…¥ï¼Œä½†ä¸éœ€è¦è·¨ step çš„æ¢¯åº¦ â†’ **å¿…é¡» `.detach()`**
- å¦‚æœéœ€è¦é«˜é˜¶æ¢¯åº¦ï¼ˆmeta-learningï¼‰â†’ ä¿ç•™æ¢¯åº¦ï¼Œä½†è¦æ³¨æ„æ˜¾å­˜

### 2. æ—¶åºæ¨¡å‹è®¾è®¡
**æ•™è®­**ï¼šæ—¶é—´åºåˆ—é¢„æµ‹ä¸èƒ½ç®€å•ä½¿ç”¨ mean poolingã€‚

**è§„åˆ™**ï¼š
- Mean poolingï¼šé€‚åˆåˆ†ç±»ä»»åŠ¡ï¼ˆæ—¶åºæ— å…³ï¼‰
- Attention poolingï¼šé€‚åˆé¢„æµ‹ä»»åŠ¡ï¼ˆå­¦ä¹ é‡è¦æ—¶é—´æ­¥ï¼‰
- Flatten + MLPï¼šåªé€‚åˆçŸ­åºåˆ—ï¼ˆseq_len < 100ï¼‰

### 3. å‚æ•°é‡æ§åˆ¶
**æ•™è®­**ï¼šFlatten æ“ä½œåœ¨é•¿åºåˆ—ä¸Šä¼šå¯¼è‡´å‚æ•°çˆ†ç‚¸ã€‚

**è§„åˆ™**ï¼š
- è¾“å…¥ç»´åº¦ = seq_len Ã— d_model
- seq_len=512, d_model=256 â†’ 131K è¾“å…¥ç»´åº¦
- ç¬¬ä¸€å±‚ Linear(131K, hidden) â†’ å‚æ•°é‡çˆ†ç‚¸

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨ Attention pooling å…ˆé™ç»´
- æˆ–è€…åªä½¿ç”¨æœ€åå‡ ä¸ª token

### 4. å®éªŒé…ç½®ä¸€è‡´æ€§
**æ•™è®­**ï¼šç¦»çº¿è®­ç»ƒå’Œåœ¨çº¿æµ‹è¯•çš„é…ç½®å¿…é¡»å®Œå…¨ä¸€è‡´ã€‚

**è§„åˆ™**ï¼š
- `data` å‚æ•°å¿…é¡»ç›¸åŒ
- `model_id` å¿…é¡»ç›¸åŒ
- æ‰€æœ‰æ¨¡å‹è¶…å‚æ•°å¿…é¡»ç›¸åŒ

---

## ğŸ“ ä¿®æ”¹æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒæ¨¡å‹
- `models/titan_stream.py`
  - æ·»åŠ  Attention Pooling forecast head
  - ä¿®æ”¹ forward æ–¹æ³•ä½¿ç”¨ attention pooling

### è®­ç»ƒæµç¨‹
- `exp/exp_long_term_forecasting.py`
  - æ·»åŠ  `.detach()` é˜²æ­¢è®¡ç®—å›¾ç´¯ç§¯
  - æ·»åŠ ä¸­é—´å˜é‡æ¸…ç†

### åœ¨çº¿æµ‹è¯•
- `exp/exp_online_forecast.py`
  - ä¿®å¤ Backbone å‚æ•°åˆ†ç»„é€»è¾‘

### é…ç½®æ–‡ä»¶
- `run.py`
  - æ·»åŠ  `--forecast_hidden_dim` å‚æ•°

### å®éªŒè„šæœ¬
- `scripts/online_forecast/titan_ettm1_delayed.sh`
  - ç»Ÿä¸€ `DATA_NAME`
  - ä¼˜åŒ–è®­ç»ƒè¶…å‚æ•°

### æ–‡æ¡£
- `CLAUDE.md`
  - æ·»åŠ è®¡ç®—å›¾ç´¯ç§¯é—®é¢˜è¯´æ˜
  - æ·»åŠ  Forecast head é‡æ–°è®¾è®¡è¯´æ˜
  - æ·»åŠ å®éªŒé…ç½®ä¿®å¤è¯´æ˜
- `TITAN_STREAM_FIX_PLAN.md`
  - æ·»åŠ é—®é¢˜ 7ï¼šè®¡ç®—å›¾ç´¯ç§¯

---

## âœ… éªŒè¯æ¸…å•

è¿è¡Œå®éªŒå‰æ£€æŸ¥ï¼š
- [ ] `temp_memory` å’Œ `temp_momentum` æœ‰ `.detach()`
- [ ] ç¦»çº¿å’Œåœ¨çº¿ä½¿ç”¨ç›¸åŒçš„ `--data` å‚æ•°
- [ ] `--patience` è®¾ç½®åˆç†ï¼ˆå»ºè®® â‰¥ 5ï¼‰
- [ ] `--lradj cosine` ä½¿ç”¨å¹³æ»‘è¡°å‡
- [ ] Forecast head ä½¿ç”¨ Attention Pooling

è¿è¡Œå®éªŒåæ£€æŸ¥ï¼š
- [ ] æ¯ä¸ª epoch è€—æ—¶ç¨³å®šï¼ˆä¸å¢é•¿ï¼‰
- [ ] Checkpoint æˆåŠŸåŠ è½½ï¼ˆæ—  warningï¼‰
- [ ] Backbone Params > 0ï¼ˆå‚æ•°åˆ†ç»„æ­£ç¡®ï¼‰
- [ ] è®­ç»ƒ loss å¹³æ»‘ä¸‹é™
- [ ] éªŒè¯ loss ä¸è¿‡æ—©åœæ­¢

---

## ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®

1. **è¿è¡Œå®Œæ•´å®éªŒ**ï¼šä½¿ç”¨ä¿®å¤åçš„é…ç½®é‡æ–°è®­ç»ƒ
2. **å¯¹æ¯”å®éªŒ**ï¼šä¸æ—§ç‰ˆæœ¬å¯¹æ¯”ï¼ŒéªŒè¯æ”¹è¿›æ•ˆæœ
3. **æ¶ˆèå®éªŒ**ï¼šæµ‹è¯• Attention Pooling vs Mean Pooling
4. **å¯è§†åŒ–**ï¼šç»˜åˆ¶ attention weightsï¼Œåˆ†ææ¨¡å‹å…³æ³¨å“ªäº›æ—¶é—´æ­¥
5. **è¶…å‚æ•°æœç´¢**ï¼šè°ƒä¼˜ `forecast_hidden_dim`, `n_persistent` ç­‰å‚æ•°

---

**ä¿®å¤å®Œæˆæ—¶é—´**ï¼š2025-12-11
**ä¿®å¤äººå‘˜**ï¼šClaude (Sonnet 4.5)
**éªŒè¯çŠ¶æ€**ï¼šå¾…å®éªŒéªŒè¯
